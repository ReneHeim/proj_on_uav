{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6893e5ad304ce55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T11:15:57.872716Z",
     "start_time": "2025-03-19T11:15:57.864416Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): ...7_week5_products_uav_data\\output\\extract\\20241029_week8_project_0_IMG_0002_6.tif.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m20241207_week5_products_uav_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mextract\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m20241029_week8_project_0_IMG_0002_6.tif.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the Parquet file into a Polars DataFrame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display the first few rows\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mmax\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/UAV-2/lib/python3.12/site-packages/polars/_utils/deprecation.py:119\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    116\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    117\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/UAV-2/lib/python3.12/site-packages/polars/_utils/deprecation.py:119\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    116\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    117\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/UAV-2/lib/python3.12/site-packages/polars/io/parquet/functions.py:252\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, allow_missing_columns)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/UAV-2/lib/python3.12/site-packages/polars/_utils/deprecation.py:93\u001b[0m, in \u001b[0;36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/UAV-2/lib/python3.12/site-packages/polars/lazyframe/frame.py:2188\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, _check_order, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2186\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): ...7_week5_products_uav_data\\output\\extract\\20241029_week8_project_0_IMG_0002_6.tif.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "# Path to the Parquet file\n",
    "file_path = r\"D:\\20241207_week5_products_uav_data\\output\\extract\\20241029_week8_project_0_IMG_0002_6.tif.parquet\"\n",
    "\n",
    "# Load the Parquet file into a Polars DataFrame\n",
    "df = pl.read_parquet(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "max(df[\"band2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43959404df02ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D:\\20241207_week5_products_uav_data\\output\\extract\\20241029_week8_project_0_IMG_0000_6.tif.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497480b2f97ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def latlon_to_utm32n_series(lat_deg, lon_deg):\n",
    "    \"\"\"\n",
    "    Convert geographic coordinates (lat, lon in degrees, WGS84)\n",
    "    to UTM Zone 32N (EPSG:32632) using the standard UTM formulas.\n",
    "\n",
    "    Returns:\n",
    "      (easting, northing) in meters.\n",
    "    \"\"\"\n",
    "    # WGS84 ellipsoid constants\n",
    "    a = 6378137.0                       # semi-major axis (meters)\n",
    "    f = 1 / 298.257223563               # flattening\n",
    "    e2 = 2*f - f**2                     # eccentricity squared\n",
    "    e = math.sqrt(e2)\n",
    "\n",
    "    # UTM parameters for Zone 32N\n",
    "    k0 = 0.9996\n",
    "    E0 = 500000.0                       # false easting\n",
    "    N0 = 0.0                            # false northing (northern hemisphere)\n",
    "    lambda0 = math.radians(9.0)         # central meridian for Zone 32N (9Â°E)\n",
    "\n",
    "    # Convert input latitude and longitude from degrees to radians\n",
    "    phi = math.radians(lat_deg)\n",
    "    lam = math.radians(lon_deg)\n",
    "\n",
    "    # Compute auxiliary values\n",
    "    N_val = a / math.sqrt(1 - e2 * math.sin(phi)**2)\n",
    "    T = math.tan(phi)**2\n",
    "    # Second eccentricity squared\n",
    "    ep2 = e2 / (1 - e2)\n",
    "    C = ep2 * math.cos(phi)**2\n",
    "    A = (lam - lambda0) * math.cos(phi)\n",
    "\n",
    "    # Meridional arc length (M)\n",
    "    M = a * (\n",
    "          (1 - e2/4 - 3*e2**2/64 - 5*e2**3/256) * phi\n",
    "        - (3*e2/8 + 3*e2**2/32 + 45*e2**3/1024) * math.sin(2*phi)\n",
    "        + (15*e2**2/256 + 45*e2**3/1024) * math.sin(4*phi)\n",
    "        - (35*e2**3/3072) * math.sin(6*phi)\n",
    "    )\n",
    "\n",
    "    # Calculate Easting and Northing using standard UTM series formulas\n",
    "    easting = E0 + k0 * N_val * (\n",
    "          A\n",
    "        + (1 - T + C) * A**3 / 6\n",
    "        + (5 - 18*T + T**2 + 72*C - 58*ep2) * A**5 / 120\n",
    "    )\n",
    "\n",
    "    northing = N0 + k0 * (\n",
    "          M\n",
    "        + N_val * math.tan(phi) * (\n",
    "              A**2 / 2\n",
    "            + (5 - T + 9*C + 4*C**2) * A**4 / 24\n",
    "            + (61 - 58*T + T**2 + 600*C - 330*ep2) * A**6 / 720\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return easting, northing\n",
    "\n",
    "\n",
    "# Test the function with a known point\n",
    "\n",
    "coord = [9.9181978710164600, 51.5649526394502686]\n",
    "easting, northing = latlon_to_utm32n_series(coord[1], coord[0])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Latitude: {coord[1]}, Longitude: {coord[0]}\")\n",
    "print(f\"Easting: {easting:.2f} m, Northing: {northing:.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79845880bfcf84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71561b2bb113e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the GPKG file\n",
    "file_path =  \"/run/media/mak/OS/example_data_week8/20241029_products_uav_data/20241204_oncerco_plot_polygons.gpkg\"\n",
    "gdf = gpd.read_file(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(gdf.head())\n",
    "print(gdf.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa957e6cad98fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad493044d1c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.shape)  # Should show (number_of_rows, number_of_columns)\n",
    "print(gdf.isnull().sum())  # Check for missing values\n",
    "print(gdf.is_valid)  # Should return True for all rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af186fd23d836a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load camera data (adjust delimiter as needed)\n",
    "camera_df = pd.read_csv(\"/run/media/mak/OS/example_data_week8/20241029_products_uav_data/20241029_week8_cameras.txt\", sep=\"\\t\",  skiprows=2, header=None, )\n",
    "\n",
    "camera_df.columns = ['PhotoID', 'X', 'Y', 'Z', 'Omega', 'Phi', 'Kappa', 'r11', 'r12', 'r13',\n",
    "                          'r21', 'r22', 'r23', 'r31', 'r32', 'r33']\n",
    "# Create a geometry column (assuming X is longitude and Y is latitude)\n",
    "camera_df['geometry'] = camera_df.apply(lambda row: Point(row['X'], row['Y']), axis=1)\n",
    "\n",
    "# Create a GeoDataFrame with the camera data\n",
    "camera_gdf = gpd.GeoDataFrame(camera_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "camera_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4326df9323da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_in_projected = camera_gdf.to_crs(\"EPSG:32632\")\n",
    "camera_in_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c2959939ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_in_projected.plot(aspect=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cdaa5e8eae153",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"camera points\"] = camera_in_projected.geometry\n",
    "gdf.plot(aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aac728ae7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = gdf[\"geometry\"][0]\n",
    "print(polygon)\n",
    "print(gdf[\"geometry\"][0])\n",
    "i=0\n",
    "\n",
    "for point in camera_in_projected[\"geometry\"]:\n",
    "    if polygon.contains(point):\n",
    "        print(point)\n",
    "        print(camera_in_projected[\"PhotoID\"][i])\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a299e087e911651",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = gdf[\"geometry\"][5]\n",
    "for i in range(len(camera_df)):\n",
    "    point = Point(latlon_to_utm32n_series(camera_df[\"Y\"][i], camera_df[\"X\"][i]))\n",
    "   #print(f\"function point {camera_in_projected[\"geometry\"][i]} Library poinT: {point}  \" )\n",
    "    if polygon.contains(point):\n",
    "        print(camera_df[\"PhotoID\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034126b7166b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "import rasterio\n",
    "import logging\n",
    "\n",
    "def parquet_to_multiband_tif(parquet_path, output_tif, band_columns=[\"band1\", \"band2\", \"band3\"],\n",
    "                             crs=\"EPSG:32632\", nodata=None):\n",
    "    \"\"\"\n",
    "    Reads a Parquet file containing georeferenced data and writes out a multi-band GeoTIFF.\n",
    "\n",
    "    The Parquet file must include at least the following columns:\n",
    "        - \"Xw\": x-coordinate (e.g., projected easting)\n",
    "        - \"Yw\": y-coordinate (e.g., projected northing)\n",
    "    and one or more band columns (e.g., \"band1\", \"band2\", \"band3\").\n",
    "\n",
    "    Duplicate coordinate entries are aggregated by taking the mean.\n",
    "\n",
    "    Parameters:\n",
    "        parquet_path (str): Path to the input Parquet file.\n",
    "        output_tif (str): Path where the output GeoTIFF will be saved.\n",
    "        band_columns (list of str): List of column names to export as bands.\n",
    "        crs (str): Coordinate reference system for the output GeoTIFF.\n",
    "        nodata: Value to assign for missing data. If None, missing data remains as NaN.\n",
    "\n",
    "    Returns:\n",
    "        None. The GeoTIFF is written to output_tif.\n",
    "    \"\"\"\n",
    "    # Read the Parquet file using Polars and convert to a Pandas DataFrame.\n",
    "    df = pl.read_parquet(parquet_path)\n",
    "    df_pd = df.to_pandas()\n",
    "\n",
    "    # Check required coordinate columns\n",
    "    if not {\"Xw\", \"Yw\"}.issubset(df_pd.columns):\n",
    "        raise ValueError(\"The input file must contain 'Xw' and 'Yw' coordinate columns.\")\n",
    "\n",
    "    # Get unique coordinates for the grid.\n",
    "    x_unique = np.sort(df_pd[\"Xw\"].unique())\n",
    "    # For rasters, Y is sorted in descending order (top-to-bottom).\n",
    "    y_unique = np.sort(df_pd[\"Yw\"].unique())[::-1]\n",
    "\n",
    "    if len(x_unique) < 2 or len(y_unique) < 2:\n",
    "        raise ValueError(\"Not enough unique coordinate values to form a raster grid.\")\n",
    "\n",
    "    # Calculate pixel size (assumes constant spacing)\n",
    "    pixel_width = np.round(x_unique[1] - x_unique[0], 6)\n",
    "    pixel_height = np.round(abs(y_unique[0] - y_unique[1]), 6)\n",
    "\n",
    "    # Define the affine transform: origin is the top-left corner.\n",
    "    origin_x = x_unique[0]\n",
    "    origin_y = y_unique[0]\n",
    "    transform = from_origin(origin_x, origin_y, pixel_width, pixel_height)\n",
    "\n",
    "    band_arrays = []\n",
    "    for band in band_columns:\n",
    "        if band not in df_pd.columns:\n",
    "            raise ValueError(f\"Band column '{band}' not found in the input file.\")\n",
    "        print(df_pd)\n",
    "        # Group by coordinates to aggregate duplicate (Xw, Yw) pairs (using mean).\n",
    "        df_grouped = df_pd.groupby([\"Xw\", \"Yw\"], as_index=False)[band].mean()\n",
    "        # Pivot the grouped data: rows by Yw, columns by Xw.\n",
    "        pivot = df_grouped.pivot(index=\"Yw\", columns=\"Xw\", values=band)\n",
    "\n",
    "        # Reindex to ensure all coordinate positions are present in the proper order.\n",
    "        pivot = pivot.reindex(index=y_unique, columns=x_unique)\n",
    "        band_array = pivot.values\n",
    "        print(\"here\")\n",
    "\n",
    "        # Replace missing values with nodata if provided.\n",
    "        if nodata is not None:\n",
    "            band_array = np.where(np.isnan(band_array), nodata, band_array)\n",
    "        band_arrays.append(band_array)\n",
    "\n",
    "    # Use the dimensions from the first band.\n",
    "    height, width = band_arrays[0].shape\n",
    "    dtype = band_arrays[0].dtype\n",
    "\n",
    "    logging.info(f\"Raster dimensions: width={width}, height={height}\")\n",
    "    logging.info(f\"Affine Transform: {transform}\")\n",
    "    logging.info(f\"CRS: {crs}\")\n",
    "\n",
    "    # Write the multi-band GeoTIFF.\n",
    "    with rasterio.open(\n",
    "         output_tif,\n",
    "         \"w\",\n",
    "         driver=\"GTiff\",\n",
    "         height=height,\n",
    "         width=width,\n",
    "         count=len(band_columns),\n",
    "         dtype=dtype,\n",
    "         crs=crs,\n",
    "         transform=transform,\n",
    "         nodata=nodata\n",
    "    ) as dst:\n",
    "         for idx, band_array in enumerate(band_arrays, start=1):\n",
    "             dst.write(band_array, idx)\n",
    "\n",
    "    logging.info(f\"GeoTIFF successfully saved to {output_tif}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460719c438fd6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = file_path\n",
    "output_tif = \"./output.tif\"\n",
    "bands = [\"band1\", \"band2\", \"band3\"]  # adjust based on your data\n",
    "parquet_to_multiband_tif(parquet_path, output_tif, bands, crs=\"EPSG:32632\", nodata=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d860c61393907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d865d1ff12c4294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}