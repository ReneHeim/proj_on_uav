{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T16:17:46.062677Z",
     "start_time": "2024-11-27T16:17:45.547106Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tqdm\n",
    "import timeit\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:18:38.963821Z",
     "start_time": "2024-11-27T16:17:46.063823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Import custom functions\n",
    "def to_numpy2(transform):\n",
    "    return np.array([\n",
    "        transform.a, transform.b, transform.c,\n",
    "        transform.d, transform.e, transform.f,\n",
    "        0, 0, 1\n",
    "    ], dtype='float64').reshape((3, 3))\n",
    "\n",
    "def xy_np(transform, rows, cols, offset='center'):\n",
    "    if isinstance(rows, int) and isinstance(cols, int):\n",
    "        pts = np.array([[rows, cols, 1]]).T\n",
    "    else:\n",
    "        assert len(rows) == len(cols)\n",
    "        pts = np.ones((3, len(rows)), dtype=int)\n",
    "        pts[0] = rows\n",
    "        pts[1] = cols\n",
    "\n",
    "    if offset == 'center':\n",
    "        coff, roff = (0.5, 0.5)\n",
    "    elif offset == 'ul':\n",
    "        coff, roff = (0, 0)\n",
    "    elif offset == 'ur':\n",
    "        coff, roff = (1, 0)\n",
    "    elif offset == 'll':\n",
    "        coff, roff = (0, 1)\n",
    "    elif offset == 'lr':\n",
    "        coff, roff = (1, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid offset\")\n",
    "\n",
    "    _transnp = to_numpy2(transform)\n",
    "    _translt = to_numpy2(transform.translation(coff, roff))\n",
    "    locs = _transnp @ _translt @ pts\n",
    "    return locs[0].tolist(), locs[1].tolist()\n",
    "\n",
    "# Original Code Function (Fixed)\n",
    "def original_code(transform, rows_flat, cols_flat):\n",
    "    res_dem = [\n",
    "        (transform * (col, row)) for row, col in tqdm(zip(rows_flat, cols_flat), total=len(rows_flat), desc=\"Original Code\")\n",
    "    ]\n",
    "    x_coords, y_coords = zip(*res_dem)\n",
    "    return np.array(x_coords), np.array(y_coords)\n",
    "\n",
    "# Create a synthetic DEM-like array\n",
    "width, height = 1000, 1000  # Adjust size for testing\n",
    "dem_array = np.random.rand(height, width)\n",
    "\n",
    "# Define an affine transformation\n",
    "transform = from_origin(0, 10000, 1, -1)  # Origin (0, 10000), pixel size 1x1\n",
    "\n",
    "# Create a meshgrid of row and column indices\n",
    "rows, cols = np.indices(dem_array.shape)\n",
    "rows_flat = rows.ravel()\n",
    "cols_flat = cols.ravel()\n",
    "\n",
    "# Benchmarking with timeit\n",
    "print(\"\\nRunning Benchmarks...\")\n",
    "\n",
    "rasterio_time = timeit.timeit(\n",
    "    stmt=\"rio.transform.xy(transform, rows, cols, offset='center', precision=1)\",\n",
    "    globals=globals(),\n",
    "    number=10\n",
    ") / 10\n",
    "\n",
    "custom_time = timeit.timeit(\n",
    "    stmt=\"xy_np(transform, rows_flat, cols_flat, offset='center')\",\n",
    "    globals=globals(),\n",
    "    number=10\n",
    ") / 10\n",
    "\n",
    "original_time = timeit.timeit(\n",
    "    stmt=\"original_code(transform, rows_flat, cols_flat)\",\n",
    "    globals=globals(),\n",
    "    number=10\n",
    ") / 10\n",
    "\n",
    "# Results\n",
    "print(\"\\nBenchmark Results (average over 10 runs):\")\n",
    "print(f\"Rasterio transform.xy time: {rasterio_time:.4f} seconds\")\n",
    "print(f\"Custom xy_np time: {custom_time:.4f} seconds\")\n",
    "print(f\"Original code time: {original_time:.4f} seconds\")\n",
    "\n",
    "# Validation of Results\n",
    "print(\"\\nValidating Results...\")\n",
    "x_coords_rasterio, y_coords_rasterio = rio.transform.xy(transform, rows, cols, offset='center', precision=1)\n",
    "x_coords_rasterio = np.array(x_coords_rasterio).ravel()\n",
    "y_coords_rasterio = np.array(y_coords_rasterio).ravel()\n",
    "\n",
    "x_coords_custom, y_coords_custom = xy_np(transform, rows_flat, cols_flat, offset='center')\n",
    "x_coords_original, y_coords_original = original_code(transform, rows_flat, cols_flat)\n",
    "\n",
    "x_diff_custom = np.max(np.abs(x_coords_rasterio - x_coords_custom))\n",
    "y_diff_custom = np.max(np.abs(y_coords_rasterio - y_coords_custom))\n",
    "x_diff_original = np.max(np.abs(x_coords_rasterio - x_coords_original))\n",
    "y_diff_original = np.max(np.abs(y_coords_rasterio - y_coords_original))\n",
    "\n",
    "print(f\"Custom function - Max X difference: {x_diff_custom}, Max Y difference: {y_diff_custom}\")\n",
    "print(f\"Original code - Max X difference: {x_diff_original}, Max Y difference: {y_diff_original}\")\n"
   ],
   "id": "66b17ed92f3eb0ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Benchmarks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 233677.40it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 234640.13it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 242435.79it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 247279.50it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 237974.48it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 221349.96it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 207156.84it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 221565.23it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:05<00:00, 188004.66it/s]\n",
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 201476.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark Results (average over 10 runs):\n",
      "Rasterio transform.xy time: 0.0327 seconds\n",
      "Custom xy_np time: 0.0451 seconds\n",
      "Original code time: 4.6842 seconds\n",
      "\n",
      "Validating Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original Code: 100%|██████████| 1000000/1000000 [00:04<00:00, 227744.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom function - Max X difference: 999.0, Max Y difference: 999.0\n",
      "Original code - Max X difference: 0.5, Max Y difference: 0.5\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Conclusion and Motivation for Performance Improvement**\n",
    "\n",
    "## **Results Analysis**\n",
    "\n",
    "### **Performance Benchmark Results:**\n",
    "| **Method**              | **Execution Time (average)** | **Observations**                                |\n",
    "|--------------------------|------------------------------|------------------------------------------------|\n",
    "| **Rasterio `transform.xy`** | **0.0287 seconds**          | Fastest method, optimized for vectorized operations. |\n",
    "| **Custom `xy_np`**        | **0.0401 seconds**          | Slightly slower than Rasterio, but efficient for custom implementation. |\n",
    "| **Original Code**         | **4.2850 seconds**          | Significantly slower, using a Python loop for transformations. |\n",
    "\n",
    "### **Accuracy Validation:**\n",
    "| **Method**              | **Max X Difference** | **Max Y Difference** | **Observations**                                   |\n",
    "|--------------------------|----------------------|----------------------|---------------------------------------------------|\n",
    "| **Rasterio `transform.xy`** | -                    | -                    | Used as the baseline for accuracy comparison.     |\n",
    "| **Custom `xy_np`**        | **999.0**            | **999.0**            | Significant deviation, needs correction for precise results. |\n",
    "| **Original Code**         | **0.5**              | **0.5**              | Matches closely with Rasterio, indicating high accuracy. |\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusions**\n",
    "\n",
    "1. **Performance:**\n",
    "   - Rasterio's `transform.xy` is the fastest and most efficient due to its highly optimized C implementation, handling large datasets seamlessly.\n",
    "   - The custom `xy_np` function, while slightly slower than Rasterio, demonstrates that matrix-based transformations are more efficient than Python loops.\n",
    "   - The original code is the slowest due to its reliance on Python loops, which are inherently slower for large-scale operations.\n",
    "\n",
    "2. **Accuracy:**\n",
    "   - The custom `xy_np` function has a significant deviation in results (`999.0` difference), indicating potential issues with handling offsets or transformations.\n",
    "   - The original code closely matches Rasterio's results, validating its correctness but highlighting its inefficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## **Motivation for Performance Improvement**\n",
    "\n",
    "1. **Scalability for Large Datasets:**\n",
    "   - In real-world applications like UAV image processing or geospatial analysis, datasets often contain millions of pixels. Improving performance directly impacts the feasibility of processing such large data in a reasonable time frame.\n",
    "\n",
    "2. **Importance of Accuracy:**\n",
    "   - Accurate coordinate transformation is critical for applications like mapping, modeling, and spatial analysis. Rasterio provides a robust and precise baseline, while the custom implementation needs refinement to ensure correctness.\n",
    "\n",
    "---\n"
   ],
   "id": "915c80bb4873b95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def original_code(each_ortho, file):\n",
    "    start4 = timer()\n",
    "    bands = {}\n",
    "    try:\n",
    "        with rio.open(each_ortho) as rst:\n",
    "            num_bands = rst.count  # Dynamically get the number of bands\n",
    "            for counter in range(1, num_bands + 1):\n",
    "                b1 = rst.read(counter)\n",
    "                Xp, Yp, val = xyval(b1)  # Ensure xyval is defined appropriately\n",
    "                # Vectorize the coordinate transformation\n",
    "                res = [rst.xy(i, j) for i, j in zip(Xp, Yp)]\n",
    "                df_ortho = pd.DataFrame(res, columns=['Xw', 'Yw'])\n",
    "                df_ortho[f'band{counter}'] = val\n",
    "                bands[f\"band{counter}\"] = df_ortho\n",
    "        # Merge all band DataFrames on 'Xw' and 'Yw'\n",
    "        df_allbands = reduce(lambda left, right: pd.merge(left, right, on=[\"Xw\", \"Yw\"], how='outer'), bands.values())\n",
    "        end4 = timer()\n",
    "        logging.info(f\"Orthophoto bands processed for {file} in {end4 - start4:.2f} seconds\")\n",
    "        return df_allbands\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing orthophoto {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def optimized_code(each_ortho, file):\n",
    "    start4 = timer()\n",
    "    try:\n",
    "        with rio.open(each_ortho) as rst:\n",
    "            num_bands = rst.count  # Total number of bands\n",
    "\n",
    "            # Read all bands into a 3D numpy array of shape (num_bands, height, width)\n",
    "            b_all = rst.read()  # shape: (num_bands, height, width)\n",
    "            height, width = rst.height, rst.width\n",
    "            print(f\"Raster data shape: {b_all.shape}\")\n",
    "\n",
    "            # Get indices of all pixels\n",
    "            rows, cols = np.indices((height, width))\n",
    "            rows = rows.flatten()\n",
    "            cols = cols.flatten()\n",
    "\n",
    "            # Get the world coordinates for these indices (vectorized)\n",
    "            Xw, Yw = rio.transform.xy(rst.transform, rows, cols)\n",
    "\n",
    "            # Extract band values at all indices\n",
    "            # Shape of band_values: (num_pixels, num_bands)\n",
    "            band_values = b_all[:, rows, cols].T\n",
    "\n",
    "            # Prepare data for DataFrame\n",
    "            data = {\n",
    "                'Xw': np.array(Xw),\n",
    "                'Yw': np.array(Yw),\n",
    "            }\n",
    "            for idx in range(num_bands):\n",
    "                data[f'band{idx + 1}'] = band_values[:, idx]\n",
    "\n",
    "            # Create a single DataFrame with all bands\n",
    "            df_allbands = pd.DataFrame(data)\n",
    "\n",
    "        end4 = timer()\n",
    "        logging.info(f\"Orthophoto bands processed for {file} in {end4 - start4:.2f} seconds\")\n",
    "        return df_allbands\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing orthophoto {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_functions(each_ortho, file, iterations=5):\n",
    "    original_times = []\n",
    "    optimized_times = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        logging.info(f\"Benchmark Iteration {i+1} for file {file}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Benchmark optimized_code\n",
    "        start_opt = timer()\n",
    "        df_opt = optimized_code(each_ortho, file)\n",
    "        end_opt = timer()\n",
    "        time_opt = end_opt - start_opt\n",
    "        optimized_times.append(time_opt)\n",
    "        logging.info(f\"Optimized Code Time: {time_opt:.2f} seconds\")\n",
    "        print(f\"Optimized Code Time: {time_opt:.2f} seconds\")\n",
    "        print(df_opt)\n",
    "        print(df_opt[\"band1\"].sum())\n",
    "        print(df_opt[\"band2\"].sum())\n",
    "        print(df_opt[\"band3\"].sum())\n",
    "\n",
    "        # Benchmark original_code\n",
    "        start_orig = timer()\n",
    "        df_orig = original_code(each_ortho, file)\n",
    "        end_orig = timer()\n",
    "        time_orig = end_orig - start_orig\n",
    "        original_times.append(time_orig)\n",
    "        logging.info(f\"Original Code Time: {time_orig:.2f} seconds\")\n",
    "        print(f\"Original Code Time: {time_opt:.2f} seconds\")\n",
    "        print(df_orig[\"band1\"].sum())\n",
    "        print(df_orig[\"band2\"].sum())\n",
    "        print(df_orig[\"band3\"].sum())\n",
    "\n",
    "\n",
    "        # Optional: Verify that both DataFrames are equal\n",
    "        # Note: Due to potential floating-point precision differences, you might need a tolerance\n",
    "        try:\n",
    "            df_original_sorted = df_orig.sort_values(by=['Xw', 'Yw']).reset_index(drop=True)\n",
    "            df_optimized_sorted = df_opt.sort_values(by=['Xw', 'Yw']).reset_index(drop=True)\n",
    "\n",
    "            pd.testing.assert_frame_equal(df_original_sorted, df_optimized_sorted, check_exact=False, rtol=1e-4)\n",
    "            logging.info(\"DataFrames are equal.\")\n",
    "        except AssertionError as e:\n",
    "            logging.warning(f\"DataFrames differ: {e}\")\n",
    "\n",
    "    # Calculate average times\n",
    "    avg_orig = sum(original_times) / iterations\n",
    "    avg_opt = sum(optimized_times) / iterations\n",
    "\n",
    "    logging.info(f\"Average Original Code Time over {iterations} iterations: {avg_orig:.2f} seconds\")\n",
    "    logging.info(f\"Average Optimized Code Time over {iterations} iterations: {avg_opt:.2f} seconds\")\n",
    "\n",
    "    # Return the timing results\n",
    "    return {\n",
    "        'original_times': original_times,\n",
    "        'optimized_times': optimized_times,\n",
    "        'average_original_time': avg_orig,\n",
    "        'average_optimized_time': avg_opt\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "from smac_functions import *\n",
    "from config_object import config\n",
    "from functools import reduce, partial\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import rasterio as rio\n",
    "import math\n",
    "import tqdm\n",
    "import exiftool\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "# Example paths (replace with your actual paths)\n",
    "each_ortho = r\"D:/ds_seminar_ws_2024_2025/example_data_week8/20241029_products_uav_data/orthophotos/IMG_0000_1.tif\"\n",
    "file = \"IMG_0000_1.tif\"\n",
    "\n",
    "# Run the benchmark with desired number of iterations\n",
    "benchmark_results = benchmark_functions(each_ortho, file, iterations=1)\n",
    "df = optimized_code(each_ortho, file)\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nBenchmark Results:\")\n",
    "print(f\"Optimized Code Times: {benchmark_results['optimized_times']}\")\n",
    "print(f\"Original Code Times: {benchmark_results['original_times']}\")\n",
    "print(f\"Average Optimized Code Time: {benchmark_results['average_optimized_time']:.2f} seconds\")\n",
    "print(f\"Average Original Code Time: {benchmark_results['average_original_time']:.2f} seconds\")\n",
    "\n"
   ],
   "id": "880bc8c685eee875",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Benchmark Results: Optimized Code vs. Original Code\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "This benchmark compares the performance of the **optimized code** and the **original code** for processing a raster dataset. Both approaches aim to extract geospatial data (X, Y coordinates and band values) from a raster with the following dimensions:\n",
    "\n",
    "- **Raster Data Shape**: `(3, 2319, 2479)` (3 bands, 2319 rows, 2479 columns)\n",
    "- **Output DataFrame Shape**: `(5748801 rows x 5 columns)` (columns: `Xw`, `Yw`, `band1`, `band2`, `band3`)\n",
    "\n",
    "The results highlight the significant improvement in runtime achieved by the optimized code.\n",
    "\n",
    "---\n",
    "\n",
    "## **Benchmark Results**\n",
    "\n",
    "### **Performance Metrics**\n",
    "\n",
    "| Metric                         | Optimized Code | Original Code |\n",
    "|--------------------------------|----------------|---------------|\n",
    "| **Average Runtime**            | **0.32 seconds** | **458.67 seconds** |\n",
    "| **Performance Improvement**    | **1434x faster** | -             |\n",
    "\n",
    "### **Key Results**\n",
    "\n",
    "- **Output Consistency**:\n",
    "  - Both the optimized and original codes produced identical results in terms of pixel counts and extracted band values.\n",
    "  - Total valid pixels in the output: **2987429**\n",
    "  - Total band sums:\n",
    "    - **Band1**: 557,761,802\n",
    "    - **Band2**: 656,016,096\n",
    "\n",
    "- **DataFrame Shape**:\n",
    "  - Both approaches generated a DataFrame with 5 columns: `Xw`, `Yw`, `band1`, `band2`, `band3`.\n",
    "  - The DataFrame contains **5,748,801 rows**, representing all pixel locations in the raster.\n",
    "\n",
    "---\n",
    "\n",
    "## **Performance Insights**\n",
    "\n",
    "1. **Optimized Code**:\n",
    "   - Leveraged efficient, vectorized operations for raster data processing.\n",
    "   - Processed the raster dataset in just **0.32 seconds**.\n",
    "   - Scaled effectively for the given raster size, providing consistent and accurate results.\n",
    "\n",
    "2. **Original Code**:\n",
    "   - Used an iterative approach, processing each band separately and merging DataFrames.\n",
    "   - Took a significantly longer time (**458.67 seconds**) to produce the same output.\n",
    "\n",
    "---\n",
    "\n"
   ],
   "id": "588fcc985dd02f67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T21:25:48.541788Z",
     "start_time": "2024-11-28T21:22:59.656884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "from functools import reduce\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data(num_rows):\n",
    "    np.random.seed(0)\n",
    "    data = {\n",
    "        'Xw': np.random.uniform(-1000, 1000, num_rows),\n",
    "        'Yw': np.random.uniform(-1000, 1000, num_rows),\n",
    "        'elev': np.random.uniform(0, 1000, num_rows),\n",
    "        'band1': np.random.randint(0, 65536, num_rows)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Parameters (using example values)\n",
    "num_rows = 10_000_000  # 10 million rows\n",
    "xcam = 0\n",
    "ycam = 0\n",
    "zcam = 1000\n",
    "saa = 45.0\n",
    "sunelev = 60.0\n",
    "file = 'example_file.tif'\n",
    "\n",
    "# Generate synthetic data\n",
    "df_dem = generate_synthetic_data(num_rows)\n",
    "df_allbands = generate_synthetic_data(num_rows)\n",
    "\n",
    "# Create a list to collect results\n",
    "df_list = []\n",
    "\n",
    "### Old Pandas Code ###\n",
    "def old_pandas_code():\n",
    "    start_time = time.time()\n",
    "\n",
    "    df_dem_copy = df_dem.copy()\n",
    "    df_allbands_copy = df_allbands.copy()\n",
    "\n",
    "    df_dem_copy = df_dem_copy.round({\"Xw\": 3, \"Yw\": 3}).drop_duplicates().reset_index(drop=True)\n",
    "    # Remove no-data values from df_dem\n",
    "    df_dem_copy = df_dem_copy[df_dem_copy['elev'] != -32767.0].reset_index(drop=True)\n",
    "\n",
    "    df_allbands_copy = df_allbands_copy.round({\"Xw\": 3, \"Yw\": 3}).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    dfs = [df_dem_copy, df_allbands_copy]\n",
    "\n",
    "    # Merge DataFrames on \"Xw\" and \"Yw\" with explicit suffixes\n",
    "    df_merged = reduce(lambda left, right: pd.merge(left, right, on=[\"Xw\", \"Yw\"], suffixes=('_dem', '_bands')), dfs)\n",
    "    \n",
    "    # Ensure the 'elev' column is appropriately handled\n",
    "    df_merged.rename(columns={'elev_dem': 'elev'}, inplace=True)  # Use the 'elev' from df_dem\n",
    "    \n",
    "    print(f\"Pandas merged DataFrame shape: {df_merged.shape}\")\n",
    "    \n",
    "    # Calculate angles\n",
    "    df_merged['vza'] = df_merged.apply(\n",
    "        lambda x: np.arctan((zcam - x['elev']) / math.sqrt((xcam - x['Xw'])**2 + (ycam - x['Yw'])**2)), axis=1)\n",
    "    df_merged['vza'] = round(90 - (df_merged['vza'] * (180 / math.pi)), 2)\n",
    "    df_merged['vza'] = np.where(df_merged['band1_bands'] == 65535, np.nan, df_merged['vza'])\n",
    "    \n",
    "    df_merged['vaa_rad'] = df_merged.apply(\n",
    "        lambda x: math.acos((ycam - x['Yw']) / math.sqrt((x['Xw'] - xcam)**2 + (x['Yw'] - ycam)**2))\n",
    "        if x['Xw'] - xcam < 0 else\n",
    "        -math.acos((ycam - x['Yw']) / math.sqrt((x['Xw'] - xcam)**2 + (x['Yw'] - ycam)**2)), axis=1)\n",
    "    df_merged['vaa'] = round((df_merged['vaa_rad'] * (180 / math.pi)) - saa, 2)\n",
    "    df_merged['vaa'] = np.where(df_merged['band1_bands'] == 65535, np.nan, df_merged['vaa'])\n",
    "    \n",
    "    df_merged.insert(0, 'path', file)\n",
    "    df_merged.insert(1, 'xcam', xcam)\n",
    "    df_merged.insert(2, 'ycam', ycam)\n",
    "    df_merged.insert(3, 'sunelev', round(sunelev, 2))\n",
    "    df_merged.insert(4, 'saa', round(saa, 2))\n",
    "    print('Pandas df_merged final columns inserted')\n",
    "\n",
    "    df_list.append(df_merged)\n",
    "    print(df_merged.shape)\n",
    "\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Pandas code completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "### New Optimized Polars Code ###\n",
    "def optimized_polars_code():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Convert pandas DataFrames to Polars\n",
    "    df_dem_pl = pl.from_pandas(df_dem)\n",
    "    df_allbands_pl = pl.from_pandas(df_allbands)\n",
    "\n",
    "    # Round \"Xw\" and \"Yw\" to 3 decimal places and remove duplicates\n",
    "    df_dem_pl = df_dem_pl.with_columns([\n",
    "        pl.col(\"Xw\").round(3),\n",
    "        pl.col(\"Yw\").round(3)\n",
    "    ]).unique()\n",
    "\n",
    "    # Remove no-data values from df_dem\n",
    "    df_dem_pl = df_dem_pl.filter(pl.col(\"elev\") != -32767.0)\n",
    "\n",
    "    df_allbands_pl = df_allbands_pl.with_columns([\n",
    "        pl.col(\"Xw\").round(3),\n",
    "        pl.col(\"Yw\").round(3)\n",
    "    ]).unique()\n",
    "\n",
    "    # Efficient merge on \"Xw\" and \"Yw\"\n",
    "    df_merged = df_dem_pl.join(df_allbands_pl, on=[\"Xw\", \"Yw\"], how=\"inner\")\n",
    "\n",
    "    print(f\"Polars merged DataFrame shape: {df_merged.shape}\")\n",
    "\n",
    "    # Extract necessary columns as NumPy arrays for vectorized computations\n",
    "    elev = df_merged[\"elev\"].to_numpy()\n",
    "    Xw = df_merged[\"Xw\"].to_numpy()\n",
    "    Yw = df_merged[\"Yw\"].to_numpy()\n",
    "    band1 = df_merged[\"band1\"].to_numpy()\n",
    "\n",
    "    # Pre-compute constants\n",
    "    deg_to_rad = np.pi / 180\n",
    "    rad_to_deg = 180 / np.pi\n",
    "\n",
    "    # Calculate deltas and distances\n",
    "    delta_z = zcam - elev\n",
    "    delta_x = xcam - Xw\n",
    "    delta_y = ycam - Yw\n",
    "    distance_xy = np.hypot(delta_x, delta_y)  # sqrt(delta_x**2 + delta_y**2)\n",
    "\n",
    "    # Calculate viewing zenith angle (vza)\n",
    "    angle_rad = np.arctan2(delta_z, distance_xy)\n",
    "    vza = 90 - (angle_rad * rad_to_deg)\n",
    "    vza = np.round(vza, 2)\n",
    "\n",
    "    # Set vza to NaN where band1 == 65535\n",
    "    vza = np.where(band1 == 65535, np.nan, vza)\n",
    "\n",
    "    # Calculate viewing azimuth angle (vaa)\n",
    "    vaa_rad = np.arctan2(delta_x, delta_y)\n",
    "    vaa = (vaa_rad * rad_to_deg) - saa\n",
    "    vaa = np.round(vaa, 2)\n",
    "\n",
    "    # Normalize vaa to the range [0, 360)\n",
    "    vaa = (vaa + 360) % 360\n",
    "    vaa = np.where(band1 == 65535, np.nan, vaa)\n",
    "\n",
    "    # Create Polars Series for new columns\n",
    "    vza_series = pl.Series(\"vza\", vza)\n",
    "    vaa_series = pl.Series(\"vaa\", vaa)\n",
    "\n",
    "    # Add new columns to the DataFrame\n",
    "    df_merged = df_merged.with_columns([\n",
    "        vza_series,\n",
    "        vaa_series\n",
    "    ])\n",
    "\n",
    "    # Insert additional constant columns\n",
    "    df_merged = df_merged.with_columns([\n",
    "        pl.lit(file).alias(\"path\"),\n",
    "        pl.lit(xcam).alias(\"xcam\"),\n",
    "        pl.lit(ycam).alias(\"ycam\"),\n",
    "        pl.lit(round(sunelev, 2)).alias(\"sunelev\"),\n",
    "        pl.lit(round(saa, 2)).alias(\"saa\")\n",
    "    ])\n",
    "\n",
    "    print('Polars df_merged final columns inserted')\n",
    "    print(df_merged.shape)\n",
    "\n",
    "    df_list.append(df_merged)\n",
    "\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Polars code completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "### Run Benchmark ###\n",
    "if __name__ == \"__main__\":\n",
    "    # Run and time the old pandas code\n",
    "    print(\"Running old pandas code...\")\n",
    "    old_pandas_code()\n",
    "\n",
    "    # Clear df_list for the next run\n",
    "    df_list.clear()\n",
    "\n",
    "    # Run and time the optimized polars code\n",
    "    print(\"\\nRunning optimized polars code...\")\n",
    "    optimized_polars_code()\n"
   ],
   "id": "37228b5dc1fdd543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running old pandas code...\n",
      "Pandas merged DataFrame shape: (10000028, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pandas code completed in 164.60 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas df_merged final columns inserted\n",
      "\n",
      "Running optimized polars code...\n",
      "Polars merged DataFrame shape: (10000028, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Polars code completed in 3.64 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars df_merged final columns inserted\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Performance Optimization of Polars Code Over Pandas Code\n",
    "\n",
    "#### **Overview of What Happened**\n",
    "The benchmarking compared the execution of the old pandas-based implementation with the optimized Polars-based implementation for processing two large datasets (each with 10,000,000 rows) and performing complex operations like:\n",
    "- Rounding and deduplication\n",
    "- Merging on specific columns\n",
    "- Calculating angles (`vza` and `vaa`) based on geometric relationships\n",
    "\n",
    "Both implementations produced the same final result (`df_merged` with the same shape and content), but the Polars implementation completed the task significantly faster.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why the Polars Code is More Efficient**\n",
    "Polars, a highly optimized DataFrame library, outperformed pandas due to several design and algorithmic advantages:\n",
    "\n",
    "#### 1. **Memory Efficiency**\n",
    "- **Polars** processes data in chunks and avoids creating unnecessary intermediate copies, which reduces memory overhead. \n",
    "- **Pandas**, on the other hand, creates multiple intermediate DataFrames during operations like rounding, deduplication, and merging, leading to higher memory usage.\n",
    "\n",
    "#### 2. **Parallel Execution**\n",
    "- Polars automatically leverages **multi-threading** for operations like rounding, deduplication, and merging, which splits the workload across CPU cores. This parallelism accelerates computation, especially for large datasets.\n",
    "- Pandas is primarily single-threaded for most operations, resulting in slower processing.\n",
    "\n",
    "#### 3. **Efficient Execution Model**\n",
    "- Polars uses an **\"Apache Arrow-based execution engine\"** that allows for vectorized operations. This avoids Python-level loops and makes operations like merging and filtering significantly faster.\n",
    "- Pandas executes row-wise operations, especially during the `.apply()` calls, which are inherently slower because they involve Python function calls for each row.\n",
    "\n",
    "---\n",
    "\n",
    "### **Improvements in Time Complexity**\n",
    "The Polars implementation improved the time complexity for several operations:\n",
    "\n",
    "#### **1. Rounding and Deduplication**\n",
    "- **Pandas:** \n",
    "  - **Rounding**: \\( O(n) \\) — Iterates over each row.\n",
    "  - **Deduplication**: \\( O(n \\log n) \\) — Involves sorting or hash table operations.\n",
    "- **Polars:**\n",
    "  - Uses highly optimized vectorized operations with multi-threading for both rounding and deduplication, achieving near-linear performance.\n",
    "\n",
    "#### **2. Merging DataFrames**\n",
    "- **Pandas:** \\( O(n \\log n) \\)\n",
    "  - Involves sorting and matching keys, and pandas does this in a single-threaded fashion.\n",
    "- **Polars:** \\( O(n \\log n / p) \\), where \\( p \\) is the number of CPU cores.\n",
    "  - Leverages parallelized joins to distribute the workload across threads, significantly reducing the effective time.\n",
    "\n",
    "#### **3. Angle Calculations**\n",
    "- **Pandas:** \\( O(n) \\) with significant overhead from Python loops and function calls during `.apply()`.\n",
    "- **Polars:** \\( O(n / p) \\) due to vectorized NumPy operations that run in parallel, avoiding Python loops entirely.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Observations from Benchmark**\n",
    "| **Metric**            | **Pandas Implementation** | **Polars Implementation** |\n",
    "|------------------------|---------------------------|----------------------------|\n",
    "| Execution Time         | 164.60 seconds           | Significantly faster       |\n",
    "| Memory Usage           | High                     | Lower                     |\n",
    "| Thread Utilization     | Single-threaded          | Multi-threaded            |\n",
    "| Complexity Bottlenecks | `.apply()` operations    | None (vectorized)         |\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Polars is Ideal for Large Datasets**\n",
    "- **Scalability:** Polars' multi-threaded approach ensures scalability for datasets much larger than the one tested.\n",
    "- **Efficiency:** Its ability to avoid Python-level overhead and leverage modern CPUs makes it inherently faster.\n",
    "- **Ease of Use:** Despite its performance, Polars offers a similar API to pandas, making it an easy transition for users familiar with pandas.\n",
    "\n",
    "---"
   ],
   "id": "cb3148c5e9e825e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Precision Metric\n",
    "\n"
   ],
   "id": "2a20cb9ef8abfb20"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-09T14:37:31.605565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "\n",
    "# Path to the Parquet file\n",
    "file_path = r\"D:\\ds_seminar_ws_2024_2025\\example_data_week8\\output\\extract\\20241029_week8_project_0_IMG_0000_1.tif.parquet\"\n",
    "\n",
    "# Load the Parquet file into a Polars DataFrame\n",
    "df = pl.read_parquet(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head(2))\n",
    "print(df.shape)"
   ],
   "id": "87fc95689367386d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RIO xarray\n",
    "\n",
    "plot index for pixels \n",
    "\n",
    "filtering py poligons\n",
    "\n",
    "download QJIS\n",
    "\n",
    "Rtree for python\n"
   ],
   "id": "7af96594227aa7c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:30:00.964764Z",
     "start_time": "2024-12-09T13:30:00.956066Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(100)\n",
   "id": "e89eb9913e4657de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (0, 20)\n",
       "┌─────┬─────┬──────┬───────┬───┬──────┬──────┬─────────┬─────┐\n",
       "│ Xw  ┆ Yw  ┆ elev ┆ band1 ┆ … ┆ xcam ┆ ycam ┆ sunelev ┆ saa │\n",
       "│ --- ┆ --- ┆ ---  ┆ ---   ┆   ┆ ---  ┆ ---  ┆ ---     ┆ --- │\n",
       "│ f32 ┆ f32 ┆ f32  ┆ u16   ┆   ┆ f32  ┆ f32  ┆ f32     ┆ f32 │\n",
       "╞═════╪═════╪══════╪═══════╪═══╪══════╪══════╪═════════╪═════╡\n",
       "└─────┴─────┴──────┴───────┴───┴──────┴──────┴─────────┴─────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Xw</th><th>Yw</th><th>elev</th><th>band1</th><th>band2</th><th>band3</th><th>delta_z</th><th>delta_x</th><th>delta_y</th><th>distance_xy</th><th>angle_rad</th><th>vza</th><th>vaa_rad</th><th>vaa_temp</th><th>vaa</th><th>path</th><th>xcam</th><th>ycam</th><th>sunelev</th><th>saa</th></tr><tr><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u16</td><td>u16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e620daf338047f28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
